## 1.差分隐私的承诺
“差分隐私”描述的是一种由数据持有者或监管者所作出的对于数据学科的承诺：“允许你的数据应用于任意的研究或分析，即使是可以获取到其他的研究成果，数据集或是信息资源，你也不会因此而受到负面或其他方面的影响。”在最好的情况下，不需要借助于数据清洗空间，数据使用协议，数据保护计划，或其他受限制的查看，差分隐私数据库机制能够使得机密的数据被广泛地应用于精确的数据分析中。尽管如此，数据的有用性也会减少：信息恢复的基础规则表明对于许多问题过于精确的回答将会以一种特殊的方式破坏隐私。基于差分隐私算法研究的目标是尽可能延缓这种不可避免性。
差分隐私处理的是一种矛盾，这种矛盾是指在研究人口相关的有用信息时，不能学习到任何有关个人的信息。一个医学类的数据库可能告诉我们抽烟会导致癌症，这影响了一个保险类公司对于一个吸烟者的长期药物花费的看法。吸烟者是否因此受到了分析结果的损害？或许，如果保险公司知道他抽烟，他要缴纳的保险费可能会提高。但他也可能会因此受益：当他明白存在的健康风险时，他可能会决定戒烟。吸烟者的隐私是否得到保障？很明确的是比起研究之前，人们知道了更多有关抽烟者的信息，但是他的信息是否“泄漏”了？差分隐私认为并没有泄漏个人隐私，用一种合理的观点解释：对于一个抽烟者的影响与他的信息是否被用于研究是相互独立的。这是一个在研究中得到的结论，不因为他个人数据是否在数据集中，而影响到一个抽烟者。

差分隐私机制保证了相同的结论，例如，吸烟者导致癌症，与个人是否选择将自己的个人信息添加到数据库中是相互独立的。特别地，它保证任何输出的序列（查询响应）“基本”上，与任意个体信息是否存在与数据库中，是独立发生的。在此，它的概率取决于采用的差分隐私机制（由数据监管者所控制的）的随机选择。这里的“基本”，由参数 &epsilon; 来决定。越小的&epsilon;将产生越强的隐私保护（而响应的精确性会越差）。

差分隐私是一种定义，而非一种算法。对于给定的计算任务_T_和给定的一个&epsilon;值，有多种差分隐私的算法可以实现满足&epsilon;-差分隐私方式的_T_。其中一些算法会比其他的算法有更好的隐私性。当&epsilon;很小时，寻找一种对于_T_精确性高的&epsilon;-差分隐私算法是很困难的。这种困难程度高于寻找一个对于特定计算任务所要求结果的数值稳定算法。



#### 1.1差分隐私保护的数据分析
差分隐私是一种隐私定义，应用于差分隐私保护数据分析的问题。我们简短地说明一些有关这一问题的其它方法所存在的问题。

_数据不能完全匿名化且保证有用性_。通常来说，越丰富的数据，越有趣并且有用。这就引出了“匿名化”和“去除个人身份标识信息”的概念，这些是希望可以让一部分数据被禁止访问，而其余数据公开或用于分析。然而，数据的丰富性能够使得通过一些意外的数据集或是一些属性来“判别”是某个个体。例如，邮政编码、出生日期和性别的组合，甚至是三部最近观看的影片和大约观看的时间的组合。这种“判别”能力能够应用于对于在不同数据库中匿名记录和非匿名记录的链接攻击中。因此，麻塞诸塞州政府的医学记录可以通过相应的带有投票登记记录的匿名医疗经历数据进行链接攻击。另外，在一个推荐类的竞赛中，网飞公司公开的训练数据，包含用户观看记录的匿名电影记录数据集，这些网飞公司的用户可以通过访问IMDb进行链接攻击，从而确定属于某个用户的信息。


差分隐私可以使得链接攻击无效：因为满足差分隐私机制是数据访问机制的一个性质，它与攻击者是否掌握辅助信息无关。比起那些不在训练集的人来说，处在网飞公司训练集中个人信息不会因为通过访问IMDb而增加其受到链接攻击的风险。

_匿名化的记录重识别不是唯一的风险_。

_基于大数据集的查询不具有保护性_。

_查询审查是存在问题的_。

_概况统计是不安全的_




#### 1.2相关文献说明

























